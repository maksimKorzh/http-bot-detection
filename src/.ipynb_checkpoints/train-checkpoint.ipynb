{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/2\n",
      "6400/6400 [==============================]6400/6400 [==============================] - 7s 1ms/step - loss: 0.1227 - acc: 0.8725 - val_loss: 0.0323 - val_acc: 0.9675\n",
      "\n",
      "Epoch 2/2\n",
      "6400/6400 [==============================]6400/6400 [==============================] - 7s 1ms/step - loss: 0.1515 - acc: 0.8481 - val_loss: 0.0795 - val_acc: 0.9187\n",
      "\n",
      "2000/2000 [==============================]2000/2000 [==============================] - 0s 228us/step\n",
      "\n",
      "\n",
      "Test accuracy: 0.9245\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 0\n",
      "Actual: 1   Predicted: 0\n",
      "Actual: 0   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 0   Predicted: 0\n",
      "Actual: 1   Predicted: 1\n",
      "Actual: 1   Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(4353,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# load data file stream\n",
    "with open('./train_data/data.csv') as f:\n",
    "    data = []\n",
    "    row = csv.reader(f)\n",
    "    \n",
    "    # loop over data entries in CSV\n",
    "    for batch in range(10365152):\n",
    "        # parse next row\n",
    "        next_row = next(row)\n",
    "        request = json.loads(next_row[0])\n",
    "        is_bot = int(next_row[1])\n",
    "        data.append([request, is_bot])\n",
    "        \n",
    "        # batch data\n",
    "        if (batch + 1) == 10000:\n",
    "            # validation split (80% to 20%)\n",
    "            validation_split = int(len(data) - len(data) * 0.2)\n",
    "            \n",
    "            # define train & test data\n",
    "            train_data = []\n",
    "            train_labels = []\n",
    "            test_data = []\n",
    "            test_labels = []\n",
    "            \n",
    "            # shuffle data\n",
    "            #random.shuffle(data)\n",
    "\n",
    "            # init train & test datasets\n",
    "            for i in range(len(data)):\n",
    "                if i < validation_split:\n",
    "                    train_data.append(data[i][0])\n",
    "                    train_labels.append(data[i][1])\n",
    "                \n",
    "                else:\n",
    "                    test_data.append(data[i][0])\n",
    "                    test_labels.append(data[i][1])\n",
    "            \n",
    "            # convert data to numpy arrays\n",
    "            train_data = np.array(train_data)\n",
    "            train_labels = np.array(train_labels)\n",
    "            test_data = np.array(test_data)\n",
    "            test_labels = np.array(test_labels)\n",
    "            \n",
    "            # load existing model\n",
    "            try: model = keras.models.load_model('model')\n",
    "            except: pass\n",
    "            \n",
    "            # train model\n",
    "            model.fit(\n",
    "                train_data,\n",
    "                train_labels,\n",
    "                validation_split=0.2,\n",
    "                epochs=2\n",
    "            )\n",
    "\n",
    "            # test model            \n",
    "            test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "            print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "            # print sample predictions\n",
    "            predicted = model.predict(test_data[:30])\n",
    "            for i in range(len(predicted)):\n",
    "                print('Actual:', test_labels[i], '  Predicted:', int(predicted[i]))\n",
    "\n",
    "            # free up data\n",
    "            data = []\n",
    "            \n",
    "            # save model\n",
    "            model.save('model')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
